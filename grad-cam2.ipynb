{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.8.0].\n",
      "device:[cuda].\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as TD\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "# from resnet import *\n",
    "from resnet3 import *\n",
    "from torch.utils.model_zoo import load_url\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "np.set_printoptions(precision=3)\n",
    "torch.set_printoptions(precision=3)\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x\n",
    "\n",
    "class ModelOutputs():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, feature_module, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            if module == self.feature_module:\n",
    "                target_activations, x = self.feature_extractor(x)\n",
    "            elif \"avgpool\" in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0),-1)\n",
    "            else:\n",
    "                x = module(x) \n",
    "\n",
    "        return target_activations, x \n",
    "\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model, feature_module, target_layer_names, device):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "        model.to(device)\n",
    "\n",
    "        self.extractor = ModelOutputs(self.model, self.feature_module, target_layer_names)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        return self.model(input_img)\n",
    "\n",
    "    def __call__(self, input_img, target_category=None):\n",
    "        input_img = input_img.to(self.device)\n",
    "\n",
    "        features, output = self.extractor(input_img)\n",
    "\n",
    "        if target_category == None:\n",
    "            target_category = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][target_category] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = one_hot.to(device)\n",
    "        \n",
    "        one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.feature_module.zero_grad()\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "        \n",
    "        #print(self.extractor.get_gradients(),len(self.extractor.get_gradients()))\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features[-1]\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]\n",
    "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, input_img.shape[2:])\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      " + in-dist train len     :  6000\n",
      " + in-dist test  len     :  5788\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets,transforms\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "ds = datasets.ImageFolder('./data/CUB_200_2011/images',transform=transform_train)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(ds, [6000, 5788])\n",
    "classes = 200\n",
    "    \n",
    "#outdist_iter = torch.utils.data.DataLoader(outdist_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "\n",
    "print (\"=\"*30)\n",
    "print(' + in-dist train len     : ',len(train_dataset))\n",
    "print(' + in-dist test  len     : ',len(test_dataset))\n",
    "#print(' + out-dist len          : ',len(outdist_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval_base(model,data_iter,device):\n",
    "    with torch.no_grad():\n",
    "        n_total,n_correct,epis_unct_sum,alea_unct_sum = 0,0,0,0\n",
    "        y_probs= list()\n",
    "        model.eval() # evaluate (affects DropOut and BN)\n",
    "        for batch_in,batch_out in data_iter:\n",
    "            # Foraward path\n",
    "            y_trgt      = batch_out.to(device)\n",
    "            out,feats     = model.forward(batch_in.to(device))\n",
    "            #out     = model.forward(batch_in.to(device))\n",
    "\n",
    "            # Check predictions\n",
    "            y_prob,y_pred    = torch.max(out,1)\n",
    "            n_correct   += (y_pred==y_trgt).sum().item()\n",
    "            n_total     += batch_in.size(0)\n",
    "            \n",
    "            y_probs += list(y_prob.cpu().numpy())\n",
    "            \n",
    "        val_accr  = (n_correct/n_total)\n",
    "        model.train() # back to train mode \n",
    "        out_eval = {'val_accr':val_accr, 'y_prob' : y_probs}\n",
    "    return out_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimzier(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "\n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Resnet , Grad-CAM, CE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "#resnet = models.resnet18(pretrained=True)\n",
    "#num_ftrs = resnet.fc.in_features\n",
    "#resnet.fc = nn.Linear(num_ftrs, 200)   \n",
    "\n",
    "resnet = resnet18(pretrained=True, **{'num_classes':classes}).to(device)\n",
    "resnet.layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1  |  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn1  |  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu  |  ReLU(inplace=True)\n",
      "conv2  |  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2  |  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in resnet.named_children(): # 모든 layer에 대해서 직접 접근\n",
    "    if name in 'layer4': # target_layer라면 해당 layer에서의 gradient를 저장\n",
    "        for sub_name, sub_module in module[len(module)-1].named_children():\n",
    "            print(sub_name,' | ',sub_module )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3989a43dbd6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Forward path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#out = resnet.forward(batch_in.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "grad_cam = GradCam(model=resnet, feature_module=resnet.layer4, target_layer_names=[\"1\"], device=device)\n",
    "\n",
    "warm = 1.\n",
    "optm = optim.SGD(resnet.parameters(), lr=1e-3,momentum=0.9)\n",
    "#optm = optim.Adam(resnet.parameters(), lr=1e-3)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optm, T_max=220)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optm, milestones=[60, 120, 180], gamma=0.2)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS,print_every = 200, 1\n",
    "loss_global = list()\n",
    "acc_global = list()\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0.0\n",
    "    batch_ind = 0\n",
    "    scheduler.step(epoch)\n",
    "\n",
    "    for batch_in,batch_out in train_iter:\n",
    "        # Forward path\n",
    "        out,feats = resnet.forward(batch_in.to(device)) \n",
    "        #out = resnet.forward(batch_in.to(device)) \n",
    "        \n",
    "        loss = ce(out, batch_out.to(device))\n",
    "\n",
    "        #loss = loss_out['mace_avg'] + 0.1*pi_loss\n",
    "        #print(loss_out['mace_avg'].data, loss_out['epis_avg'].data, loss_out['alea_avg'].data, )\n",
    "        # Update\n",
    "        optm.zero_grad() # reset gradient \n",
    "        loss.backward() # back-propagation \n",
    "        optm.step() # optimizer update\n",
    "        # Track losses \n",
    "        loss_sum += loss\n",
    "        batch_ind+=1 \n",
    "        \n",
    "        #cam = grad_cam(batch_in[0].unsqueeze(0).to(device))\n",
    "        #plt.figure(figsize=(12,12))\n",
    "        #plt.subplot(2,2,1)\n",
    "        #plt.imshow(batch_in[0].permute(1,2,0))\n",
    "        #plt.subplot(2,2,2)\n",
    "        #plt.imshow(cam, cmap=plt.get_cmap('jet'))\n",
    "        #plt.show()\n",
    "        \n",
    "    loss_avg = loss_sum/len(train_iter)\n",
    "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
    "        test_res = func_eval_base(resnet,test_iter,device)\n",
    "        #outdist_res  = func_eval_base(model,outdist_iter,device)\n",
    "        loss_global.append(loss_avg)\n",
    "        acc_global.append(test_res['val_accr'])\n",
    "        #print (\"epoch:[%d/%d] loss:[%.3f] test_accr:[%.3f] \"%(epoch,EPOCHS,loss_avg,test_res['val_accr'])) \n",
    "        #print (\" [indist]  alea:[%.3f] epis:[%.7f]\\n [outdist] alea:[%.3f] epis:[%.7f]\"%(test_res['alea'],test_res['epis'], outdist_res['alea'],outdist_res['epis']))\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(4,4,1)\n",
    "        plt.title(\"loss\")\n",
    "        plt.plot(loss_global)\n",
    "        plt.subplot(4,4,2)\n",
    "        plt.title(\"acc :: \"+str(test_res['val_accr']))\n",
    "        plt.plot(acc_global)\n",
    "        plt.subplot(4,4,3)\n",
    "        plt.imshow(batch_in[0].permute(1,2,0))\n",
    "        plt.subplot(4,4,4)\n",
    "        cam = grad_cam(batch_in[0].unsqueeze(0).to(device))\n",
    "        plt.imshow(batch_in[0].permute(1,2,0))\n",
    "        plt.imshow(cam, alpha=0.45, cmap=plt.get_cmap('jet'))\n",
    "        plt.show();\n",
    "    \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Resnet-MLN , U-CAM, Uncertainity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureOfLogits(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim     = 64,   # input feature dimension \n",
    "                 y_dim      = 10,   # number of classes \n",
    "                 k          = 5,    # number of mixtures\n",
    "                 sig_min    = 1e-4, # minimum sigma\n",
    "                 sig_max    = None, # maximum sigma\n",
    "                 SHARE_SIG  = True  # share sigma among mixture\n",
    "                 ):\n",
    "        super(MixtureOfLogits,self).__init__()\n",
    "        self.in_dim     = in_dim    # Q\n",
    "        self.y_dim      = y_dim     # D\n",
    "        self.k          = k         # K\n",
    "        self.sig_min    = sig_min\n",
    "        self.sig_max    = sig_max\n",
    "        self.SHARE_SIG  = SHARE_SIG\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.h_dim = 256\n",
    "        self.fc_pi      = nn.Sequential(nn.BatchNorm1d(self.in_dim),\n",
    "                                        nn.Linear(self.in_dim,self.h_dim),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(self.h_dim),\n",
    "                                        nn.Linear(self.h_dim,self.k))\n",
    "                                        \n",
    "        self.fc_mu      = nn.Sequential(nn.BatchNorm1d(self.in_dim),\n",
    "                                        nn.Linear(self.in_dim,self.h_dim),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(self.h_dim),\n",
    "                                        nn.Linear(self.h_dim,self.k*self.y_dim))\n",
    "        if self.SHARE_SIG:\n",
    "            self.fc_sigma   = nn.Sequential(nn.BatchNorm1d(self.in_dim),\n",
    "                                        nn.Linear(self.in_dim,self.h_dim),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(self.h_dim),\n",
    "                                        nn.Linear(self.h_dim,self.k))\n",
    "        else:\n",
    "            self.fc_sigma   = nn.Sequential(nn.BatchNorm1d(self.in_dim),\n",
    "                                        nn.Linear(self.in_dim,self.h_dim),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(self.h_dim),\n",
    "                                        nn.Linear(self.h_dim,self.k))\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            :param x: [N x Q]\n",
    "        \"\"\"\n",
    "        pi_logit        = self.fc_pi(x)                                 # [N x K]\n",
    "        pi              = torch.softmax(pi_logit,dim=1)                 # [N x K]\n",
    "        mu              = self.fc_mu(x)                                 # [N x KD]\n",
    "        mu              = torch.reshape(mu,(-1,self.k,self.y_dim))      # [N x K x D]\n",
    "        mu              = F.sigmoid(mu)\n",
    "        #mu              = F.softmax(mu, dim=-1)\n",
    "        if self.SHARE_SIG:\n",
    "            sigma       = self.fc_sigma(x)                              # [N x K]\n",
    "            sigma       = sigma.unsqueeze(dim=-1)                       # [N x K x 1]\n",
    "            sigma       = sigma.expand_as(mu)                           # [N x K x D]\n",
    "        else:\n",
    "            sigma       = self.fc_sigma(x)                              # [N x KD]\n",
    "        sigma           = torch.reshape(sigma,(-1,self.k,self.y_dim))   # [N x K x D]\n",
    "        if self.sig_max is None:\n",
    "            sigma = self.sig_min + torch.exp(sigma)                     # [N x K x D]\n",
    "        else:\n",
    "            sig_range = (self.sig_max-self.sig_min)\n",
    "            sigma = self.sig_min + sig_range*torch.sigmoid(sigma)       # [N x K x D]\n",
    "        mol_out = {'pi':pi,'mu':mu,'sigma':sigma}\n",
    "        return mol_out\n",
    "\n",
    "class MixtureLogitNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 name       = 'mln',        # name\n",
    "                 h_dim      = 512,          # itermediate feature dimension\n",
    "                 y_dim      = 10,           # output dimension\n",
    "                 USE_BN     = True,         # whether to use batch-norm\n",
    "                 k          = 5,            # number of mixtures\n",
    "                 sig_min    = 1e-4,         # minimum sigma\n",
    "                 sig_max    = 10,           # maximum sigma\n",
    "                 mu_min     = -3,           # minimum mu (init)\n",
    "                 mu_max     = +3,           # maximum mu (init)\n",
    "                 SHARE_SIG  = True,    \n",
    "                 base       = None \n",
    "                 ):\n",
    "        super(MixtureLogitNetwork,self).__init__()\n",
    "        self.name       = name\n",
    "        self.h_dim      = h_dim\n",
    "        self.y_dim      = y_dim\n",
    "        self.USE_BN     = USE_BN\n",
    "        self.k          = k\n",
    "        self.sig_min    = sig_min\n",
    "        self.sig_max    = sig_max\n",
    "        self.mu_min     = mu_min\n",
    "        self.mu_max     = mu_max\n",
    "        self.SHARE_SIG  = SHARE_SIG\n",
    "        self.base       = base\n",
    "        self.build_graph()\n",
    "        self.init_param()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def build_graph(self):\n",
    "        # Conv layers\n",
    "        if self.base is None:\n",
    "            self.base = resnet18(pretrained=True, **{'num_classes':classes})\n",
    "        \n",
    "        # Final mixture of logits layer\n",
    "        self.mol = MixtureOfLogits(\n",
    "            in_dim      = 512,  \n",
    "            y_dim       = self.y_dim, \n",
    "            k           = self.k,\n",
    "            sig_min     = self.sig_min,\n",
    "            sig_max     = self.sig_max,\n",
    "            SHARE_SIG   = self.SHARE_SIG\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        bs = x.size(0)\n",
    "        feat = self.base(x)\n",
    "        feat = self.avgpool(feat)\n",
    "        feat = feat.view(feat.size(0),-1)\n",
    "        mln_out = self.mol(feat)\n",
    "        return mln_out # mu:[N x K x D] / pi:[N x K] / sigma:[N x K x D]\n",
    "\n",
    "    def init_param(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d): # init conv\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            if isinstance(m,nn.Linear): # lnit dense\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                \n",
    "        # Heuristic: fc_mu.bias ~ Uniform(mu_min,mu_max)\n",
    "        self.mol.fc_mu[1].bias.data.uniform_(self.mu_min,self.mu_max)\n",
    "        self.mol.fc_mu[-1].bias.data.uniform_(self.mu_min,self.mu_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:       (2, 3, 224, 224)\n",
      "=>\n",
      "pi:    (2, 3)\n",
      "[[0.544 0.343 0.114]\n",
      " [0.131 0.226 0.644]]\n",
      "mu:    (2, 3, 200)\n",
      "[[[0.939 0.171 0.896 ... 0.951 0.958 0.027]\n",
      "  [0.13  0.238 0.995 ... 0.143 0.284 0.681]\n",
      "  [0.177 0.561 0.198 ... 0.372 0.043 0.721]]\n",
      "\n",
      " [[0.715 0.489 0.501 ... 0.885 0.152 0.172]\n",
      "  [0.188 0.957 0.643 ... 0.216 0.584 0.35 ]\n",
      "  [0.627 0.614 0.237 ... 0.746 0.355 0.517]]]\n",
      "sigma: (2, 3, 200)\n",
      "[[[1.048 1.048 1.048 ... 1.048 1.048 1.048]\n",
      "  [6.148 6.148 6.148 ... 6.148 6.148 6.148]\n",
      "  [9.295 9.295 9.295 ... 9.295 9.295 9.295]]\n",
      "\n",
      " [[8.933 8.933 8.933 ... 8.933 8.933 8.933]\n",
      "  [4.149 4.149 4.149 ... 4.149 4.149 4.149]\n",
      "  [0.711 0.711 0.711 ... 0.711 0.711 0.711]]]\n",
      "=>\n",
      "mace:[4.299] epis:[0.019] alea:[0.565]\n"
     ]
    }
   ],
   "source": [
    "def np2tc(x_np): return torch.from_numpy(x_np).float().to(device)\n",
    "def tc2np(x_tc): return x_tc.detach().cpu().numpy()\n",
    "\n",
    "def mln_gather(pi,mu,sigma):\n",
    "    \"\"\"\n",
    "        :param pi:      [N x K]\n",
    "        :param mu:      [N x K x D]\n",
    "        :param sigma:   [N x K x D]\n",
    "    \"\"\"\n",
    "    max_idx = torch.argmax(pi,dim=1) # [N]\n",
    "    idx_gather = max_idx.unsqueeze(dim=-1).repeat(1,mu.shape[2]).unsqueeze(1) # [N x 1 x D]\n",
    "    mu_sel = torch.gather(mu,dim=1,index=idx_gather).squeeze(dim=1) # [N x D]\n",
    "    sigma_sel = torch.gather(sigma,dim=1,index=idx_gather).squeeze(dim=1) # [N x D]\n",
    "    out = {'max_idx':max_idx, # [N]\n",
    "           'idx_gather':idx_gather, # [N x 1 x D]\n",
    "           'mu_sel':mu_sel, # [N x D]\n",
    "           'sigma_sel':sigma_sel # [N x D]\n",
    "           }\n",
    "    return out\n",
    "\n",
    "oneDivSqrtTwoPI = 1.0 / np.sqrt(2.0*np.pi)\n",
    "def gaussian_distribution(y, mu, sigma):\n",
    "    result = (y.expand_as(mu) - mu) * torch.reciprocal(sigma)\n",
    "    result = -0.5 * (result * result)\n",
    "    return (torch.exp(result) * torch.reciprocal(sigma)) * oneDivSqrtTwoPI\n",
    "\n",
    "def mace_loss(pi,mu,sigma,target):\n",
    "    \"\"\"\n",
    "        :param pi:      [N x K]\n",
    "        :param mu:      [N x K x D]\n",
    "        :param sigma:   [N x K x D]\n",
    "        :param target:  [N x D]\n",
    "    \"\"\"\n",
    "    # $\\mu$\n",
    "    mu_hat = torch.softmax(mu,dim=2) # logit to prob [N x K x D]\n",
    "    log_mu_hat = torch.log(mu_hat+1e-6) # [N x K x D]\n",
    "    # $\\pi$\n",
    "    pi_usq = torch.unsqueeze(pi,2) # [N x K x 1]\n",
    "    pi_exp = pi_usq.expand_as(mu) # [N x K x D]\n",
    "    ### self distributed labeling\n",
    "    # target\n",
    "    target_usq =  torch.unsqueeze(target,1) # [N x 1 x D]\n",
    "    target_exp =  target_usq.expand_as(mu) # [N x K x D]\n",
    "    # CE loss\n",
    "    ce_exp = -target_exp*log_mu_hat # CE [N x K x D]\n",
    "    ace_exp = ce_exp / sigma # attenuated CE [N x K x D]\n",
    "    mace_exp = torch.mul(pi_exp,ace_exp) # mixtured attenuated CE [N x K x D]\n",
    "    mace = torch.sum(mace_exp,dim=1) # [N x D]\n",
    "    mace = torch.sum(mace,dim=1) # [N]\n",
    "    mace_avg = torch.mean(mace) # [1]\n",
    "    # Compute uncertainties (epis and alea)\n",
    "    unct_out = mln_uncertainties(pi,mu,sigma)\n",
    "    epis = unct_out['epis'] # [N]\n",
    "    alea = unct_out['alea'] # [N]\n",
    "    epis_avg = torch.mean(epis) # [1]\n",
    "    alea_avg = torch.mean(torch.log(alea)) # [1]\n",
    "    # Return\n",
    "    loss_out = {'mace':mace, # [N]\n",
    "                'mace_avg':mace_avg, # [1]\n",
    "                'epis':epis, # [N]\n",
    "                'alea':alea, # [N]\n",
    "                'epis_avg':epis_avg, # [1]\n",
    "                'alea_avg':alea_avg # [1]\n",
    "                }\n",
    "    return loss_out\n",
    "\n",
    "def mln_uncertainties(pi,mu,sigma):\n",
    "    \"\"\"\n",
    "        :param pi:      [N x K]\n",
    "        :param mu:      [N x K x D]\n",
    "        :param sigma:   [N x K x D]\n",
    "    \"\"\"\n",
    "    # $\\pi$\n",
    "    mu_hat = torch.softmax(mu,dim=2) # logit to prob [N x K x D]\n",
    "    pi_usq = torch.unsqueeze(pi,2) # [N x K x 1]\n",
    "    pi_exp = pi_usq.expand_as(sigma) # [N x K x D]\n",
    "    # softmax($\\mu$) average\n",
    "    mu_hat_avg = torch.sum(torch.mul(pi_exp,mu_hat),dim=1).unsqueeze(1) # [N x 1 x D]\n",
    "    mu_hat_avg_exp = mu_hat_avg.expand_as(mu) # [N x K x D]\n",
    "    mu_hat_diff_sq = torch.square(mu_hat-mu_hat_avg_exp) # [N x K x D]\n",
    "    # Epistemic uncertainty\n",
    "    epis = torch.sum(torch.mul(pi_exp,mu_hat_diff_sq), dim=1)  # [N x D]\n",
    "    epis = torch.sqrt(torch.sum(epis,dim=1) + 1e-4) # [N]\n",
    "    # Aleatoric uncertainty\n",
    "    alea = torch.sum(torch.mul(pi_exp,sigma), dim=1)  # [N x D]\n",
    "    alea = torch.sqrt(torch.mean(alea,dim=1) + 1e-4) # [N]\n",
    "    # Return\n",
    "    unct_out = {'epis':epis, # [N]\n",
    "                'alea':alea  # [N]\n",
    "                }\n",
    "    return unct_out\n",
    "    \n",
    "# Demo forward path of MLN\n",
    "M           = MixtureLogitNetwork(k=3,SHARE_SIG=True, y_dim=200).to(device)\n",
    "x           = torch.rand(2,3,224,224).to(device)\n",
    "target      = F.one_hot(torch.randint(low=0,high=200,size=(2,)),num_classes=200).to(device) \n",
    "mln_out     = M.forward(x)\n",
    "pi,mu,sigma = mln_out['pi'],mln_out['mu'],mln_out['sigma']\n",
    "mu_sel      = mln_gather(pi,mu,sigma)['mu_sel']\n",
    "loss_out    = mace_loss(pi,mu,sigma,target)\n",
    "loss        = loss_out['mace_avg'] - loss_out['epis_avg'] # epis as a regularizer \n",
    "loss.backward() # backward propagation \n",
    "print (\"x:       %s\"%(tc2np(x).shape,))\n",
    "print (\"=>\")\n",
    "print (\"pi:    %s\\n%s\"%(tc2np(pi).shape,tc2np(pi)))\n",
    "print (\"mu:    %s\\n%s\"%(tc2np(mu).shape,tc2np(mu)))\n",
    "print (\"sigma: %s\\n%s\"%(tc2np(sigma).shape,tc2np(sigma)))\n",
    "print (\"=>\")\n",
    "print (\"mace:[%.3f] epis:[%.3f] alea:[%.3f]\"%\n",
    "       (loss_out['mace_avg'],loss_out['epis_avg'],loss_out['alea_avg']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputsBase():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, feature_module, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations = []\n",
    "        for name, module in self.model.base._modules.items():\n",
    "            #print('name : ',name,' -> ', x)\n",
    "            if module == self.feature_module:\n",
    "                target_activations, x = self.feature_extractor(x)\n",
    "            elif \"avgpool\" in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0),-1)\n",
    "                break\n",
    "            else:\n",
    "                x = module(x) \n",
    "\n",
    "        return target_activations, x \n",
    "\n",
    "class GradCam_mln:\n",
    "    def __init__(self, model, feature_module, target_layer_names, device):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "        model.to(device)\n",
    "\n",
    "        self.extractor = ModelOutputsBase(self.model, self.feature_module, target_layer_names)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        return self.model(input_img)\n",
    "\n",
    "    def __call__(self, input_img, target_category=None):\n",
    "        input_img = input_img.to(self.device)\n",
    "\n",
    "        features, output = self.extractor(input_img) # output [B x 4096]\n",
    "        #print(\"feat : \",output)\n",
    "        mln_out = self.model.mol(output)\n",
    "        pi,mu,sigma = mln_out['pi'],mln_out['mu'],mln_out['sigma']\n",
    "        pi ,mu, sigma = pi[0].unsqueeze(0), mu[0].unsqueeze(0), sigma[0].unsqueeze(0)\n",
    "\n",
    "        if target_category == None:\n",
    "            target_category = np.argmax(output.cpu().data.numpy())\n",
    "        \n",
    "        loss_out = mace_loss(pi,mu,sigma,target_category) \n",
    "        \n",
    "        epis = loss_out['epis_avg'] \n",
    "        alea = loss_out['alea_avg'] \n",
    "\n",
    "        self.feature_module.zero_grad() \n",
    "        self.model.zero_grad() \n",
    "        epis.backward(retain_graph=True) \n",
    "        #one_hot.backward(retain_graph=True)\n",
    "        \n",
    "        #print(self.extractor.get_gradients(),len(self.extractor.get_gradients()))\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "        #print(epis,grads_val)\n",
    "\n",
    "        target = features[-1]\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]\n",
    "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, input_img.shape[2:])\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model,data_iter,device):\n",
    "    with torch.no_grad():\n",
    "        n_total,n_correct,epis_unct_sum,alea_unct_sum = 0,0,0,0\n",
    "        y_probs= list()\n",
    "        model.eval() # evaluate (affects DropOut and BN)\n",
    "        for batch_in,batch_out in data_iter:\n",
    "            # Foraward path\n",
    "            y_trgt      = batch_out.to(device)\n",
    "            mln_out     = model.forward(batch_in.to(device))\n",
    "            pi,mu,sigma = mln_out['pi'],mln_out['mu'],mln_out['sigma']\n",
    "            out         = mln_gather(pi,mu,sigma)\n",
    "            model_pred  = out['mu_sel'] # [B x N]\n",
    " \n",
    "            # Compute uncertainty \n",
    "            unct_out    = mln_uncertainties(pi,mu,sigma)\n",
    "            epis_unct   = unct_out['epis'] # [N]\n",
    "            alea_unct   = unct_out['alea'] # [N]\n",
    "            epis_unct_sum += torch.sum(epis_unct)\n",
    "            alea_unct_sum += torch.sum(alea_unct)\n",
    "\n",
    "            # Check predictions\n",
    "            y_prob,y_pred  = torch.max(model_pred,1)\n",
    "            n_correct     += (y_pred==y_trgt).sum().item()\n",
    "            n_total       += batch_in.size(0)\n",
    "            \n",
    "            y_probs += list(y_prob.cpu().numpy())\n",
    "            \n",
    "        val_accr  = (n_correct/n_total)\n",
    "        epis      = (epis_unct_sum/n_total).detach().cpu().item()\n",
    "        alea      = (alea_unct_sum/n_total).detach().cpu().item()\n",
    "        model.train() # back to train mode \n",
    "        out_eval = {'val_accr':val_accr,'epis':epis,'alea':alea, 'y_prob' : y_probs}\n",
    "    return out_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-22399.730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "0.004492052522460262\n",
      "tensor(0.010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-13998.845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "0.007601935038009675\n",
      "tensor(0.507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-14960.335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "0.0082930200414651\n",
      "tensor(0.259, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-6c2138d127cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mloss_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmln\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;31m#outdist_res  = func_eval_base(model,outdist_iter,device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss_global\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-7a747bb02ea0>\u001b[0m in \u001b[0;36mfunc_eval\u001b[0;34m(model, data_iter, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0my_probs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# evaluate (affects DropOut and BN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;31m# Foraward path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_trgt\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mbatch_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ood_mln/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kwargs = {'num_classes': classes}\n",
    "mln = MixtureLogitNetwork(name='mln',y_dim=classes,USE_BN=True,k=1,\n",
    "                                sig_min=0.01,sig_max=2, \n",
    "                                mu_min=-2,mu_max=+2,SHARE_SIG=True,\n",
    "                                base = resnet18(pretrained=True, **kwargs)).to(device)\n",
    "grad_cam_mln = GradCam_mln(model=mln, feature_module=mln.base.layer4, target_layer_names=[\"1\"], device=device)\n",
    "\n",
    "warm = 1.\n",
    "optm = optim.SGD(mln.parameters(), lr=1e-2,momentum=0.9)\n",
    "#optm = optim.Adam(resnet.parameters(), lr=1e-3)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optm, T_max=220)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optm, milestones=[60, 120, 180], gamma=0.2)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS,print_every = 200, 1\n",
    "loss_global = list()\n",
    "acc_global = list()\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0.0\n",
    "    batch_ind = 0\n",
    "    scheduler.step(epoch)\n",
    "\n",
    "    for batch_in,batch_out in train_iter:\n",
    "        # Forward path\n",
    "        mln_out = mln.forward(batch_in.to(device)) \n",
    "        pi,mu,sigma = mln_out['pi'],mln_out['mu'],mln_out['sigma']\n",
    "        target = torch.eye(classes)[batch_out].to(device)\n",
    "        loss_out = mace_loss(pi,mu,sigma,target) \n",
    "#         loss = ce(mu, batch_out.to(device))\n",
    "        loss = loss_out['mace_avg'] + 10000 * loss_out['alea_avg']  #- loss_out['epis_avg'] \n",
    "        #print(loss_out['mace_avg'].data, loss_out['epis_avg'].data, loss_out['alea_avg'].data, )\n",
    "        # Update\n",
    "        optm.zero_grad() # reset gradient \n",
    "        loss.backward() # back-propagation \n",
    "        optm.step() # optimizer update\n",
    "        # Track losses \n",
    "        loss_sum += loss\n",
    "        batch_ind+=1 \n",
    "#         print(torch.mean(sigma))\n",
    "        #ucam = grad_cam_mln(batch_in[0].unsqueeze(0).to(device), target[0].unsqueeze(0).to(device))\n",
    "        #plt.figure(figsize=(12,12))\n",
    "        #plt.subplot(2,2,1)\n",
    "        #plt.imshow(batch_in[0].permute(1,2,0))\n",
    "        #plt.subplot(2,2,2)\n",
    "        #plt.imshow(ucam, cmap=plt.get_cmap('jet'))\n",
    "        #plt.show()\n",
    "        \n",
    "    loss_avg = loss_sum/len(train_iter)\n",
    "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
    "        test_res = func_eval(mln,test_iter,device)\n",
    "        #outdist_res  = func_eval_base(model,outdist_iter,device)\n",
    "        loss_global.append(loss_avg)\n",
    "        acc_global.append(test_res['val_accr'])\n",
    "        print(loss_avg)\n",
    "        print(test_res['val_accr'])\n",
    "        print(torch.mean(sigma))\n",
    "#         #print (\"epoch:[%d/%d] loss:[%.3f] test_accr:[%.3f] \"%(epoch,EPOCHS,loss_avg,test_res['val_accr'])) \n",
    "#         #print (\" [indist]  alea:[%.3f] epis:[%.7f]\\n [outdist] alea:[%.3f] epis:[%.7f]\"%(test_res['alea'],test_res['epis'], outdist_res['alea'],outdist_res['epis']))\n",
    "#         clear_output(wait=True)\n",
    "#         plt.figure(figsize=(15,15))\n",
    "#         plt.subplot(4,4,1)\n",
    "#         plt.title(\"loss\")\n",
    "#         plt.plot(loss_global)\n",
    "#         plt.subplot(4,4,2)\n",
    "#         plt.title(\"acc :: \"+str(test_res['val_accr']))\n",
    "#         plt.plot(acc_global)\n",
    "#         plt.subplot(4,4,3)\n",
    "#         plt.imshow(batch_in[0].permute(1,2,0))\n",
    "#         plt.subplot(4,4,4)\n",
    "#         plt.title('U-CAM')\n",
    "#         cam = grad_cam_mln(batch_in.to(device), target[0].unsqueeze(0).to(device))\n",
    "#         plt.imshow(batch_in[0].permute(1,2,0))\n",
    "#         plt.imshow(cam, alpha=0.45, cmap=plt.get_cmap('jet'))\n",
    "#         plt.show();\n",
    "    \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 200])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True, **kwargs)\n",
    "state_dict = load_url('https://download.pytorch.org/models/resnet18-5c106cde.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.running_mean', 'bn1.running_var', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.1.conv1.weight', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer2.0.conv1.weight', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.1.conv1.weight', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer3.0.conv1.weight', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.1.conv1.weight', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer4.0.conv1.weight', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-8.028e-03, -5.778e-03,  6.415e-03],\n",
       "          [ 5.050e-03, -6.780e-03,  1.269e-02],\n",
       "          [ 1.333e-02,  1.452e-02,  2.452e-02]],\n",
       "\n",
       "         [[-1.988e-03,  1.247e-02,  1.049e-02],\n",
       "          [-1.936e-02, -1.670e-02, -1.186e-02],\n",
       "          [-1.157e-02, -3.767e-03, -3.468e-03]],\n",
       "\n",
       "         [[-1.144e-02, -1.388e-02,  1.156e-03],\n",
       "          [-1.791e-02, -2.935e-02, -1.388e-02],\n",
       "          [-1.406e-02, -2.699e-02, -2.396e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.304e-03, -3.117e-03, -1.330e-02],\n",
       "          [ 7.162e-03,  6.467e-03,  1.606e-02],\n",
       "          [-1.075e-02, -1.048e-02, -6.107e-03]],\n",
       "\n",
       "         [[ 7.448e-03,  6.388e-03, -1.258e-02],\n",
       "          [-7.736e-03,  1.811e-03, -1.789e-02],\n",
       "          [-2.914e-03,  7.770e-03, -9.731e-03]],\n",
       "\n",
       "         [[ 2.176e-02,  2.236e-02,  2.273e-02],\n",
       "          [ 2.668e-02,  2.913e-02,  3.336e-02],\n",
       "          [ 1.289e-02, -3.582e-03,  5.302e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.060e-02, -9.155e-03, -2.342e-02],\n",
       "          [-1.077e-02, -3.317e-03, -1.856e-02],\n",
       "          [-1.861e-02, -4.263e-03, -1.559e-02]],\n",
       "\n",
       "         [[-2.609e-02, -2.252e-02, -3.059e-02],\n",
       "          [-3.941e-02, -2.664e-02, -2.820e-02],\n",
       "          [-2.614e-02, -1.965e-02, -2.147e-02]],\n",
       "\n",
       "         [[-3.526e-03,  1.662e-03, -6.562e-03],\n",
       "          [-5.060e-03, -8.716e-04, -5.374e-03],\n",
       "          [-7.965e-03, -9.778e-03, -1.074e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.849e-02, -3.680e-03,  1.004e-02],\n",
       "          [-5.297e-03, -2.076e-02, -1.512e-02],\n",
       "          [ 2.144e-02,  6.492e-03,  4.766e-03]],\n",
       "\n",
       "         [[-1.881e-02, -6.047e-04, -7.700e-03],\n",
       "          [-1.770e-02, -7.869e-03, -1.654e-02],\n",
       "          [-1.721e-02, -2.475e-02, -3.027e-02]],\n",
       "\n",
       "         [[-3.119e-02, -1.436e-02,  2.203e-03],\n",
       "          [-1.203e-02, -2.370e-03, -1.663e-02],\n",
       "          [-1.291e-02, -1.536e-02, -3.630e-03]]],\n",
       "\n",
       "\n",
       "        [[[-3.265e-02, -4.816e-03, -2.048e-02],\n",
       "          [-2.585e-02, -1.466e-03, -2.817e-02],\n",
       "          [-2.664e-02,  4.302e-03, -2.764e-02]],\n",
       "\n",
       "         [[-6.329e-03, -1.540e-02, -1.310e-03],\n",
       "          [-1.750e-02, -2.621e-02, -2.365e-02],\n",
       "          [-7.321e-03, -1.559e-02, -8.958e-03]],\n",
       "\n",
       "         [[ 8.970e-04, -6.691e-03, -5.313e-03],\n",
       "          [-1.173e-03, -1.073e-02, -9.010e-03],\n",
       "          [ 3.231e-03, -4.585e-03,  4.351e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.182e-02, -3.689e-02, -2.259e-02],\n",
       "          [-1.305e-02, -3.419e-02, -2.724e-02],\n",
       "          [-1.238e-02, -2.345e-02, -2.249e-02]],\n",
       "\n",
       "         [[ 6.818e-03,  2.156e-02,  1.367e-02],\n",
       "          [ 3.119e-03,  1.066e-02,  1.041e-02],\n",
       "          [ 8.048e-03, -4.682e-03, -4.391e-03]],\n",
       "\n",
       "         [[-1.198e-02, -1.620e-02, -2.263e-02],\n",
       "          [-1.346e-02, -7.093e-03, -1.438e-02],\n",
       "          [-2.446e-02,  1.489e-02,  1.225e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-2.635e-02, -2.992e-02, -3.781e-02],\n",
       "          [-1.566e-02, -4.113e-03, -1.148e-02],\n",
       "          [-1.342e-02, -1.543e-02, -1.820e-02]],\n",
       "\n",
       "         [[-3.839e-03, -1.109e-02, -8.084e-04],\n",
       "          [-5.963e-03, -5.917e-03, -9.333e-03],\n",
       "          [-2.276e-03,  5.478e-03, -5.605e-03]],\n",
       "\n",
       "         [[-1.841e-03, -2.813e-03,  8.325e-03],\n",
       "          [-1.245e-03,  2.145e-04,  7.487e-03],\n",
       "          [ 1.345e-02,  3.060e-02,  2.640e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.527e-04,  2.390e-03,  6.256e-03],\n",
       "          [-1.434e-02, -2.315e-02, -1.902e-02],\n",
       "          [-2.731e-02, -3.008e-02, -3.176e-02]],\n",
       "\n",
       "         [[ 1.458e-02,  4.343e-03,  1.205e-02],\n",
       "          [-6.113e-03, -2.854e-02, -1.827e-02],\n",
       "          [-1.684e-02, -4.782e-02, -2.627e-02]],\n",
       "\n",
       "         [[-1.885e-02, -9.340e-03,  7.890e-03],\n",
       "          [-1.532e-03,  8.315e-03,  1.778e-02],\n",
       "          [-8.332e-03, -1.576e-02, -1.206e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 9.958e-03,  7.457e-03, -1.874e-03],\n",
       "          [-1.775e-03, -6.801e-04, -7.444e-03],\n",
       "          [-1.832e-02, -1.426e-02, -7.145e-03]],\n",
       "\n",
       "         [[ 7.852e-03, -2.652e-03, -1.756e-02],\n",
       "          [ 4.524e-03, -4.866e-03, -1.522e-02],\n",
       "          [-5.021e-03, -1.186e-02, -1.485e-02]],\n",
       "\n",
       "         [[ 2.916e-02,  1.034e-02,  2.474e-02],\n",
       "          [ 1.201e-02, -1.035e-02,  3.547e-03],\n",
       "          [ 8.224e-03, -1.824e-02, -5.489e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.843e-03, -4.318e-03, -5.754e-03],\n",
       "          [ 7.723e-03, -4.194e-04,  7.726e-03],\n",
       "          [ 1.354e-02,  1.570e-02,  2.089e-02]],\n",
       "\n",
       "         [[ 1.674e-03,  1.972e-03,  2.157e-02],\n",
       "          [-8.007e-03, -4.661e-03,  4.056e-03],\n",
       "          [-1.669e-02, -1.375e-02, -1.171e-02]],\n",
       "\n",
       "         [[-9.796e-03, -9.450e-03, -9.344e-03],\n",
       "          [ 6.955e-03, -3.913e-05,  6.269e-03],\n",
       "          [-1.319e-02,  9.327e-04,  1.458e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.496e-03,  5.513e-04,  1.157e-02],\n",
       "          [ 1.017e-02,  1.789e-03,  1.103e-02],\n",
       "          [ 7.021e-03,  1.465e-03,  1.277e-03]],\n",
       "\n",
       "         [[-1.302e-02,  6.411e-03, -1.520e-02],\n",
       "          [ 2.477e-02,  2.193e-02,  3.368e-02],\n",
       "          [ 2.647e-04, -3.023e-03,  1.169e-02]],\n",
       "\n",
       "         [[-2.966e-02, -1.531e-02, -1.750e-02],\n",
       "          [-1.834e-02, -2.084e-02, -1.549e-02],\n",
       "          [-1.609e-03,  1.083e-02, -1.431e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.704e-03, -2.110e-02, -2.282e-02],\n",
       "          [ 5.769e-03,  1.936e-04,  7.710e-04],\n",
       "          [-6.136e-03,  9.727e-03, -2.546e-03]],\n",
       "\n",
       "         [[ 1.104e-02,  2.421e-02,  3.421e-02],\n",
       "          [ 2.918e-02,  2.690e-02,  4.537e-02],\n",
       "          [-2.159e-02, -1.107e-03, -7.831e-03]],\n",
       "\n",
       "         [[-8.329e-03, -7.952e-03, -5.336e-03],\n",
       "          [-6.253e-04, -5.324e-03, -8.630e-03],\n",
       "          [ 3.609e-03, -1.254e-03, -4.380e-03]]]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['layer4.1.conv1.weight']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
